{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plantvillage\\Tomato___Bacterial_spot\n",
      "1702\n",
      "plantvillage\\Tomato___Early_blight\n",
      "800\n",
      "plantvillage\\Tomato___healthy\n",
      "1273\n",
      "plantvillage\\Tomato___Late_blight\n",
      "1526\n",
      "plantvillage\\Tomato___Leaf_Mold\n",
      "761\n",
      "plantvillage\\Tomato___Septoria_leaf_spot\n",
      "1417\n",
      "plantvillage\\Tomato___Spider_mites Two-spotted_spider_mite\n",
      "1341\n",
      "plantvillage\\Tomato___Target_Spot\n",
      "1123\n",
      "plantvillage\\Tomato___Tomato_mosaic_virus\n",
      "299\n",
      "plantvillage\\Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "4286\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "p = Path(\"./plantvillage/\")\n",
    "dirs = p.glob(\"*\")\n",
    "\n",
    "image_data = [] #array for the data of each image\n",
    "labels = [] #array for the labels of each image\n",
    "image_paths = [] #stores all image paths\n",
    "\n",
    "#creating a key for each label\n",
    "key = {\"Tomato___Bacterial_spot\":0,\"Tomato___Early_blight\":1,\"Tomato___healthy\":2,\"Tomato___Late_blight\":3,\"Tomato___Leaf_Mold\":4,\"Tomato___Septoria_leaf_spot\":5,\"Tomato___Spider_mites Two-spotted_spider_mite\":6,\"Tomato___Target_Spot\":7,\"Tomato___Tomato_mosaic_virus\":8,\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\":9}\n",
    "\n",
    "#for loop in order to process data\n",
    "for folder_dir in dirs:\n",
    "    label = str(folder_dir).split(\"\\\\\")[-1]\n",
    "    counter = 0\n",
    "    print(folder_dir)\n",
    "    for img_path in folder_dir.glob(\"*.JPG\"):\n",
    "        img = image.load_img(img_path,target_size=(28,28))\n",
    "        img = ImageOps.grayscale(img)\n",
    "        #img_array = image.img_to_array(img)\n",
    "        image_data.append(img)\n",
    "        labels.append(key[label])\n",
    "        counter += 1\n",
    "        \n",
    "    print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>145</td>\n",
       "      <td>147</td>\n",
       "      <td>146</td>\n",
       "      <td>142</td>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>103</td>\n",
       "      <td>107</td>\n",
       "      <td>111</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>100</td>\n",
       "      <td>116</td>\n",
       "      <td>124</td>\n",
       "      <td>119</td>\n",
       "      <td>106</td>\n",
       "      <td>115</td>\n",
       "      <td>94</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>177</td>\n",
       "      <td>165</td>\n",
       "      <td>173</td>\n",
       "      <td>152</td>\n",
       "      <td>155</td>\n",
       "      <td>168</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>113</td>\n",
       "      <td>108</td>\n",
       "      <td>115</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>116</td>\n",
       "      <td>110</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>164</td>\n",
       "      <td>158</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>170</td>\n",
       "      <td>163</td>\n",
       "      <td>153</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>163</td>\n",
       "      <td>158</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>103</td>\n",
       "      <td>118</td>\n",
       "      <td>121</td>\n",
       "      <td>118</td>\n",
       "      <td>103</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>115</td>\n",
       "      <td>129</td>\n",
       "      <td>132</td>\n",
       "      <td>119</td>\n",
       "      <td>125</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>160</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>159</td>\n",
       "      <td>161</td>\n",
       "      <td>153</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0     143     148     147     145     147     146     142     151   \n",
       "1       0     112     100     116     124     119     106     115      94   \n",
       "2       0     121     113     108     115     118     118     116     110   \n",
       "3       0     158     170     163     153     166     166     163     158   \n",
       "4       0     119     136     115     129     132     119     125     122   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0     150    ...           94        91        93        94       103   \n",
       "1     118    ...          159       161       161       177       165   \n",
       "2     118    ...          148       150       153       164       158   \n",
       "3     152    ...          127       116       117       116       103   \n",
       "4     112    ...          157       160       158       160       160   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0       107       111       107       106       112  \n",
       "1       173       152       155       168       175  \n",
       "2       164       161       159       160       162  \n",
       "3       118       121       118       103       109  \n",
       "4       160       159       161       153       159  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating inital dataframe with label values\n",
    "dummydict = {}\n",
    "df1 = pd.DataFrame(dummydict)\n",
    "df1[\"labels\"] = labels\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#for thing in image_data:\n",
    "#    for x in range(int(thing)):\n",
    "#        df[\"pixel\"+str(x)]= thing[x]\n",
    "\n",
    "listofpixelvalues = []\n",
    "\n",
    "for img in image_data:\n",
    "    listofpixelvalues.append(list(img.getdata()))\n",
    "#k,v = enumerate(listofpixelvalues[0],1)\n",
    "#[1,...784]\n",
    "k= ['pixel{}'.format(k) for k in range(1,785)]\n",
    "#print(k)\n",
    "\n",
    "df = pd.DataFrame(listofpixelvalues,columns=k)\n",
    "\n",
    "\n",
    "\n",
    "#print(listofpixelvalues[0][0])\n",
    "#print(listofpixelvalues[1][0])\n",
    "\n",
    "\n",
    "#merging the dataframes for the final product.\n",
    "df = pd.concat([df1, df], axis=1)\n",
    "df.head()\n",
    "\n",
    "\n",
    "#option to download formatted data in csv file\n",
    "#df.to_csv(\"finaldata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\home\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\home\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\home\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11622 samples, validate on 2906 samples\n",
      "Epoch 1/100\n",
      "11622/11622 [==============================] - 3s 232us/step - loss: 2.1121 - acc: 0.2862 - val_loss: 2.0046 - val_acc: 0.3014\n",
      "Epoch 2/100\n",
      "11622/11622 [==============================] - 2s 205us/step - loss: 1.9444 - acc: 0.3313 - val_loss: 1.8592 - val_acc: 0.3575\n",
      "Epoch 3/100\n",
      "11622/11622 [==============================] - 2s 205us/step - loss: 1.8076 - acc: 0.3782 - val_loss: 1.7380 - val_acc: 0.4253\n",
      "Epoch 4/100\n",
      "11622/11622 [==============================] - 2s 207us/step - loss: 1.6867 - acc: 0.4207 - val_loss: 1.6237 - val_acc: 0.4532\n",
      "Epoch 5/100\n",
      "11622/11622 [==============================] - 2s 209us/step - loss: 1.5856 - acc: 0.4600 - val_loss: 1.5229 - val_acc: 0.5041\n",
      "Epoch 6/100\n",
      "11622/11622 [==============================] - 2s 207us/step - loss: 1.4992 - acc: 0.5005 - val_loss: 1.4470 - val_acc: 0.5286\n",
      "Epoch 7/100\n",
      "11622/11622 [==============================] - 2s 208us/step - loss: 1.4285 - acc: 0.5296 - val_loss: 1.3858 - val_acc: 0.5382\n",
      "Epoch 8/100\n",
      "11622/11622 [==============================] - 2s 208us/step - loss: 1.3756 - acc: 0.5476 - val_loss: 1.3335 - val_acc: 0.5568\n",
      "Epoch 9/100\n",
      "11622/11622 [==============================] - 2s 208us/step - loss: 1.3348 - acc: 0.5541 - val_loss: 1.3068 - val_acc: 0.5602\n",
      "Epoch 10/100\n",
      "11622/11622 [==============================] - 2s 209us/step - loss: 1.2986 - acc: 0.5653 - val_loss: 1.2711 - val_acc: 0.5719\n",
      "Epoch 11/100\n",
      "11622/11622 [==============================] - 2s 207us/step - loss: 1.2745 - acc: 0.5728 - val_loss: 1.2554 - val_acc: 0.5829\n",
      "Epoch 12/100\n",
      "11622/11622 [==============================] - 2s 212us/step - loss: 1.2354 - acc: 0.5879 - val_loss: 1.2168 - val_acc: 0.5877\n",
      "Epoch 13/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 1.1982 - acc: 0.6051 - val_loss: 1.1931 - val_acc: 0.6043\n",
      "Epoch 14/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 1.1839 - acc: 0.6069 - val_loss: 1.1943 - val_acc: 0.5850\n",
      "Epoch 15/100\n",
      "11622/11622 [==============================] - 2s 211us/step - loss: 1.1514 - acc: 0.6196 - val_loss: 1.1523 - val_acc: 0.6139\n",
      "Epoch 16/100\n",
      "11622/11622 [==============================] - 2s 212us/step - loss: 1.1264 - acc: 0.6278 - val_loss: 1.1352 - val_acc: 0.6211\n",
      "Epoch 17/100\n",
      "11622/11622 [==============================] - 2s 210us/step - loss: 1.1104 - acc: 0.6336 - val_loss: 1.1355 - val_acc: 0.6318\n",
      "Epoch 18/100\n",
      "11622/11622 [==============================] - 2s 212us/step - loss: 1.0965 - acc: 0.6329 - val_loss: 1.0927 - val_acc: 0.6304\n",
      "Epoch 19/100\n",
      "11622/11622 [==============================] - 2s 210us/step - loss: 1.0736 - acc: 0.6417 - val_loss: 1.0919 - val_acc: 0.6304\n",
      "Epoch 20/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 1.0604 - acc: 0.6493 - val_loss: 1.0871 - val_acc: 0.6466\n",
      "Epoch 21/100\n",
      "11622/11622 [==============================] - 2s 215us/step - loss: 1.0341 - acc: 0.6563 - val_loss: 1.0661 - val_acc: 0.6345\n",
      "Epoch 22/100\n",
      "11622/11622 [==============================] - 3s 219us/step - loss: 1.0223 - acc: 0.6581 - val_loss: 1.0648 - val_acc: 0.6490\n",
      "Epoch 23/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 1.0082 - acc: 0.6661 - val_loss: 1.0634 - val_acc: 0.6318\n",
      "Epoch 24/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.9991 - acc: 0.6643 - val_loss: 1.0348 - val_acc: 0.6573\n",
      "Epoch 25/100\n",
      "11622/11622 [==============================] - 3s 218us/step - loss: 0.9842 - acc: 0.6684 - val_loss: 1.0251 - val_acc: 0.6497\n",
      "Epoch 26/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.9678 - acc: 0.6803 - val_loss: 1.0151 - val_acc: 0.6573\n",
      "Epoch 27/100\n",
      "11622/11622 [==============================] - 3s 226us/step - loss: 0.9522 - acc: 0.6816 - val_loss: 1.0025 - val_acc: 0.6500\n",
      "Epoch 28/100\n",
      "11622/11622 [==============================] - 3s 237us/step - loss: 0.9480 - acc: 0.6831 - val_loss: 0.9959 - val_acc: 0.6500\n",
      "Epoch 29/100\n",
      "11622/11622 [==============================] - 3s 218us/step - loss: 0.9377 - acc: 0.6872 - val_loss: 0.9833 - val_acc: 0.6559\n",
      "Epoch 30/100\n",
      "11622/11622 [==============================] - 3s 225us/step - loss: 0.9239 - acc: 0.6893 - val_loss: 0.9843 - val_acc: 0.6542\n",
      "Epoch 31/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.9153 - acc: 0.6931 - val_loss: 0.9799 - val_acc: 0.6628\n",
      "Epoch 32/100\n",
      "11622/11622 [==============================] - 2s 211us/step - loss: 0.9021 - acc: 0.7015 - val_loss: 0.9607 - val_acc: 0.6631\n",
      "Epoch 33/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.8931 - acc: 0.7009 - val_loss: 0.9551 - val_acc: 0.6652\n",
      "Epoch 34/100\n",
      "11622/11622 [==============================] - 2s 211us/step - loss: 0.8836 - acc: 0.7066 - val_loss: 0.9694 - val_acc: 0.6593\n",
      "Epoch 35/100\n",
      "11622/11622 [==============================] - 2s 212us/step - loss: 0.8804 - acc: 0.7045 - val_loss: 0.9543 - val_acc: 0.6734\n",
      "Epoch 36/100\n",
      "11622/11622 [==============================] - 2s 212us/step - loss: 0.8707 - acc: 0.7085 - val_loss: 0.9361 - val_acc: 0.6690\n",
      "Epoch 37/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.8551 - acc: 0.7132 - val_loss: 0.9372 - val_acc: 0.6765\n",
      "Epoch 38/100\n",
      "11622/11622 [==============================] - 3s 223us/step - loss: 0.8483 - acc: 0.7155 - val_loss: 0.9453 - val_acc: 0.6641\n",
      "Epoch 39/100\n",
      "11622/11622 [==============================] - 3s 219us/step - loss: 0.8406 - acc: 0.7215 - val_loss: 0.9639 - val_acc: 0.6600\n",
      "Epoch 40/100\n",
      "11622/11622 [==============================] - 3s 221us/step - loss: 0.8476 - acc: 0.7143 - val_loss: 0.9709 - val_acc: 0.6652\n",
      "Epoch 41/100\n",
      "11622/11622 [==============================] - 3s 220us/step - loss: 0.8388 - acc: 0.7210 - val_loss: 0.9178 - val_acc: 0.6844\n",
      "Epoch 42/100\n",
      "11622/11622 [==============================] - 2s 211us/step - loss: 0.8155 - acc: 0.7254 - val_loss: 0.9134 - val_acc: 0.6772\n",
      "Epoch 43/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.8021 - acc: 0.7348 - val_loss: 0.9038 - val_acc: 0.6834\n",
      "Epoch 44/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.7959 - acc: 0.7364 - val_loss: 0.9188 - val_acc: 0.6803\n",
      "Epoch 45/100\n",
      "11622/11622 [==============================] - 3s 220us/step - loss: 0.7914 - acc: 0.7358 - val_loss: 0.8911 - val_acc: 0.6889\n",
      "Epoch 46/100\n",
      "11622/11622 [==============================] - 3s 221us/step - loss: 0.7801 - acc: 0.7401 - val_loss: 0.9023 - val_acc: 0.6827\n",
      "Epoch 47/100\n",
      "11622/11622 [==============================] - 3s 221us/step - loss: 0.7707 - acc: 0.7406 - val_loss: 0.9026 - val_acc: 0.6882\n",
      "Epoch 48/100\n",
      "11622/11622 [==============================] - 3s 219us/step - loss: 0.7726 - acc: 0.7448 - val_loss: 0.8908 - val_acc: 0.6910\n",
      "Epoch 49/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.7634 - acc: 0.7494 - val_loss: 0.8896 - val_acc: 0.6862\n",
      "Epoch 50/100\n",
      "11622/11622 [==============================] - 3s 223us/step - loss: 0.7586 - acc: 0.7439 - val_loss: 0.8806 - val_acc: 0.7030\n",
      "Epoch 51/100\n",
      "11622/11622 [==============================] - 3s 220us/step - loss: 0.7446 - acc: 0.7509 - val_loss: 0.8695 - val_acc: 0.6934\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11622/11622 [==============================] - 3s 223us/step - loss: 0.7389 - acc: 0.7580 - val_loss: 0.8681 - val_acc: 0.7020\n",
      "Epoch 53/100\n",
      "11622/11622 [==============================] - 3s 227us/step - loss: 0.7303 - acc: 0.7568 - val_loss: 0.8726 - val_acc: 0.6934\n",
      "Epoch 54/100\n",
      "11622/11622 [==============================] - 3s 228us/step - loss: 0.7281 - acc: 0.7562 - val_loss: 0.8605 - val_acc: 0.6992\n",
      "Epoch 55/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.7195 - acc: 0.7584 - val_loss: 0.8613 - val_acc: 0.7041\n",
      "Epoch 56/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.7111 - acc: 0.7603 - val_loss: 0.8571 - val_acc: 0.6937\n",
      "Epoch 57/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.7169 - acc: 0.7609 - val_loss: 0.8699 - val_acc: 0.6975\n",
      "Epoch 58/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.6999 - acc: 0.7695 - val_loss: 0.8538 - val_acc: 0.7013\n",
      "Epoch 59/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.6984 - acc: 0.7672 - val_loss: 0.8589 - val_acc: 0.7023\n",
      "Epoch 60/100\n",
      "11622/11622 [==============================] - 3s 223us/step - loss: 0.6990 - acc: 0.7640 - val_loss: 0.8449 - val_acc: 0.7116\n",
      "Epoch 61/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.6834 - acc: 0.7729 - val_loss: 0.8453 - val_acc: 0.6986\n",
      "Epoch 62/100\n",
      "11622/11622 [==============================] - 2s 212us/step - loss: 0.6802 - acc: 0.7694 - val_loss: 0.8490 - val_acc: 0.7068\n",
      "Epoch 63/100\n",
      "11622/11622 [==============================] - 3s 218us/step - loss: 0.6693 - acc: 0.7778 - val_loss: 0.8503 - val_acc: 0.7003\n",
      "Epoch 64/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.6636 - acc: 0.7788 - val_loss: 0.8457 - val_acc: 0.7065\n",
      "Epoch 65/100\n",
      "11622/11622 [==============================] - 3s 230us/step - loss: 0.6637 - acc: 0.7813 - val_loss: 0.8449 - val_acc: 0.7023\n",
      "Epoch 66/100\n",
      "11622/11622 [==============================] - 3s 225us/step - loss: 0.6623 - acc: 0.7790 - val_loss: 0.8398 - val_acc: 0.7054\n",
      "Epoch 67/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.6514 - acc: 0.7807 - val_loss: 0.8332 - val_acc: 0.7099\n",
      "Epoch 68/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.6488 - acc: 0.7846 - val_loss: 0.8301 - val_acc: 0.7144\n",
      "Epoch 69/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.6448 - acc: 0.7876 - val_loss: 0.8309 - val_acc: 0.7113\n",
      "Epoch 70/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.6301 - acc: 0.7878 - val_loss: 0.8299 - val_acc: 0.7089\n",
      "Epoch 71/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.6272 - acc: 0.7914 - val_loss: 0.8332 - val_acc: 0.7027\n",
      "Epoch 72/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.6264 - acc: 0.7919 - val_loss: 0.8334 - val_acc: 0.7099\n",
      "Epoch 73/100\n",
      "11622/11622 [==============================] - 3s 215us/step - loss: 0.6215 - acc: 0.7920 - val_loss: 0.8386 - val_acc: 0.7065\n",
      "Epoch 74/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.6115 - acc: 0.7982 - val_loss: 0.8273 - val_acc: 0.7120\n",
      "Epoch 75/100\n",
      "11622/11622 [==============================] - 2s 215us/step - loss: 0.6102 - acc: 0.7950 - val_loss: 0.8217 - val_acc: 0.7189\n",
      "Epoch 76/100\n",
      "11622/11622 [==============================] - 2s 215us/step - loss: 0.6095 - acc: 0.8003 - val_loss: 0.8317 - val_acc: 0.7147\n",
      "Epoch 77/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.6001 - acc: 0.7975 - val_loss: 0.8340 - val_acc: 0.7089\n",
      "Epoch 78/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.6065 - acc: 0.7959 - val_loss: 0.8205 - val_acc: 0.7168\n",
      "Epoch 79/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.6010 - acc: 0.7997 - val_loss: 0.8564 - val_acc: 0.7072\n",
      "Epoch 80/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.5962 - acc: 0.7994 - val_loss: 0.8158 - val_acc: 0.7206\n",
      "Epoch 81/100\n",
      "11622/11622 [==============================] - 2s 215us/step - loss: 0.5868 - acc: 0.8060 - val_loss: 0.8243 - val_acc: 0.7178\n",
      "Epoch 82/100\n",
      "11622/11622 [==============================] - 3s 218us/step - loss: 0.5797 - acc: 0.8054 - val_loss: 0.8186 - val_acc: 0.7206\n",
      "Epoch 83/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.5726 - acc: 0.8086 - val_loss: 0.8147 - val_acc: 0.7189\n",
      "Epoch 84/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.5672 - acc: 0.8107 - val_loss: 0.8152 - val_acc: 0.7178\n",
      "Epoch 85/100\n",
      "11622/11622 [==============================] - 3s 219us/step - loss: 0.5657 - acc: 0.8112 - val_loss: 0.8108 - val_acc: 0.7175\n",
      "Epoch 86/100\n",
      "11622/11622 [==============================] - 2s 214us/step - loss: 0.5625 - acc: 0.8099 - val_loss: 0.8132 - val_acc: 0.7178\n",
      "Epoch 87/100\n",
      "11622/11622 [==============================] - 2s 215us/step - loss: 0.5616 - acc: 0.8159 - val_loss: 0.8245 - val_acc: 0.7116\n",
      "Epoch 88/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.5561 - acc: 0.8158 - val_loss: 0.8341 - val_acc: 0.7075\n",
      "Epoch 89/100\n",
      "11622/11622 [==============================] - 3s 215us/step - loss: 0.5559 - acc: 0.8147 - val_loss: 0.8173 - val_acc: 0.7189\n",
      "Epoch 90/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.5537 - acc: 0.8154 - val_loss: 0.8177 - val_acc: 0.7178\n",
      "Epoch 91/100\n",
      "11622/11622 [==============================] - 3s 215us/step - loss: 0.5504 - acc: 0.8149 - val_loss: 0.8127 - val_acc: 0.7189\n",
      "Epoch 92/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.5332 - acc: 0.8227 - val_loss: 0.8077 - val_acc: 0.7244\n",
      "Epoch 93/100\n",
      "11622/11622 [==============================] - 3s 218us/step - loss: 0.5312 - acc: 0.8253 - val_loss: 0.8112 - val_acc: 0.7202\n",
      "Epoch 94/100\n",
      "11622/11622 [==============================] - 2s 213us/step - loss: 0.5369 - acc: 0.8218 - val_loss: 0.8150 - val_acc: 0.7226\n",
      "Epoch 95/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.5253 - acc: 0.8272 - val_loss: 0.8096 - val_acc: 0.7185\n",
      "Epoch 96/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.5233 - acc: 0.8274 - val_loss: 0.8152 - val_acc: 0.7168\n",
      "Epoch 97/100\n",
      "11622/11622 [==============================] - 3s 218us/step - loss: 0.5269 - acc: 0.8222 - val_loss: 0.8113 - val_acc: 0.7216\n",
      "Epoch 98/100\n",
      "11622/11622 [==============================] - 3s 216us/step - loss: 0.5207 - acc: 0.8261 - val_loss: 0.8063 - val_acc: 0.7230\n",
      "Epoch 99/100\n",
      "11622/11622 [==============================] - 3s 220us/step - loss: 0.5203 - acc: 0.8286 - val_loss: 0.8164 - val_acc: 0.7206\n",
      "Epoch 100/100\n",
      "11622/11622 [==============================] - 3s 217us/step - loss: 0.5121 - acc: 0.8270 - val_loss: 0.8294 - val_acc: 0.7099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f697e151d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "train_df = df\n",
    "\n",
    "train_data = np.array(train_df,dtype='float32')\n",
    "x_train = train_data[:,1:]/255\n",
    "y_train = train_data[:,0]\n",
    "\n",
    "x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size=0.2,random_state=12345,)\n",
    "\n",
    "image = x_train[50,:].reshape((28,28))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#define the model \n",
    "im_rows = 28\n",
    "im_cols = 28\n",
    "batch_size = 512\n",
    "im_shape = (im_rows,im_cols,1)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],*im_shape)\n",
    "x_validate = x_validate.reshape(x_validate.shape[0],*im_shape)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    \n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=im_shape),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "#compile the model\n",
    "cnn_model.compile(\n",
    "loss='sparse_categorical_crossentropy',\n",
    "optimizer=Adam(lr=0.001),\n",
    "metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_model.fit(\n",
    "x_train,y_train,batch_size=batch_size,\n",
    "epochs=100,verbose=1,validation_data=(x_validate,y_validate),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
